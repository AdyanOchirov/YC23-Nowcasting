{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-11T17:25:36.063748Z",
     "iopub.status.busy": "2023-11-11T17:25:36.063389Z",
     "iopub.status.idle": "2023-11-11T17:25:40.348569Z",
     "shell.execute_reply": "2023-11-11T17:25:40.347645Z",
     "shell.execute_reply.started": "2023-11-11T17:25:36.063720Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:25:40.350736Z",
     "iopub.status.busy": "2023-11-11T17:25:40.350298Z",
     "iopub.status.idle": "2023-11-11T17:25:40.361703Z",
     "shell.execute_reply": "2023-11-11T17:25:40.360826Z",
     "shell.execute_reply.started": "2023-11-11T17:25:40.350708Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyRandomRotation:\n",
    "    def __call__(self, x):\n",
    "        angle = np.random.choice([0,90,180,270])\n",
    "        return v2.functional.rotate(x, angle)\n",
    "\n",
    "train_transform = v2.Compose([v2.RandomHorizontalFlip(p=0.5),MyRandomRotation()])\n",
    "\n",
    "TEST_TRANSFORM_LIST = [\n",
    "    v2.RandomRotation((0,0)),\n",
    "    v2.RandomRotation((90,90)),\n",
    "    v2.RandomRotation((180,180)),\n",
    "    v2.RandomRotation((270,270)),\n",
    "    v2.RandomHorizontalFlip(p=1),\n",
    "    v2.Compose([v2.RandomHorizontalFlip(p=1),v2.RandomRotation((90,90))]),\n",
    "    v2.Compose([v2.RandomHorizontalFlip(p=1),v2.RandomRotation((180,180))]),\n",
    "    v2.Compose([v2.RandomHorizontalFlip(p=1),v2.RandomRotation((270,270))]),\n",
    "]\n",
    "TEST_TRANSFORM_LIST_REVERSE = [\n",
    "    v2.RandomRotation((0,0)),\n",
    "    v2.RandomRotation((270,270)),\n",
    "    v2.RandomRotation((180,180)),\n",
    "    v2.RandomRotation((90,90)),\n",
    "    v2.RandomHorizontalFlip(p=1),\n",
    "    v2.Compose([v2.RandomRotation((270,270)),v2.RandomHorizontalFlip(p=1)]),\n",
    "    v2.Compose([v2.RandomRotation((180,180)),v2.RandomHorizontalFlip(p=1)]),\n",
    "    v2.Compose([v2.RandomRotation((90,90)),v2.RandomHorizontalFlip(p=1)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:25:40.363207Z",
     "iopub.status.busy": "2023-11-11T17:25:40.362947Z",
     "iopub.status.idle": "2023-11-11T17:25:40.394215Z",
     "shell.execute_reply": "2023-11-11T17:25:40.393426Z",
     "shell.execute_reply.started": "2023-11-11T17:25:40.363184Z"
    }
   },
   "outputs": [],
   "source": [
    "class RadarDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, folder,files,in_seq_len=4, out_seq_len=12, mode='overlap', with_time=False, full_res=True,transform=None):\n",
    "        self.in_seq_len = in_seq_len\n",
    "        self.out_seq_len = out_seq_len\n",
    "        self.seq_len = in_seq_len + out_seq_len\n",
    "        self.with_time = with_time\n",
    "        self.events = dict()\n",
    "        self.intensity = dict()\n",
    "        self.reflectivity0 = dict()\n",
    "        self.reflectivity1 = dict()\n",
    "        self.channels_per_timestamp=4\n",
    "        self.full_res=full_res\n",
    "        self.transform = transform\n",
    "        self.__prepare_dicts(folder,files)\n",
    "        self.__prepare_sequences(mode)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = []\n",
    "        for timestamp in self.sequences[index][:self.in_seq_len]:\n",
    "            x.append(self.intensity[timestamp])\n",
    "            x.append(self.events[timestamp])\n",
    "            x.append(self.reflectivity0[timestamp])\n",
    "            x.append(self.reflectivity1[timestamp])\n",
    "        x = torch.stack(x).type(torch.float32)\n",
    "        \n",
    "        y = []\n",
    "        for timestamp in self.sequences[index][self.in_seq_len:]:\n",
    "            y.append(self.intensity[timestamp])\n",
    "        if (len(y)==0):\n",
    "            y=torch.tensor([]).reshape(0,x.shape[-1],x.shape[-1])\n",
    "        else:\n",
    "            y = torch.stack(y).type(torch.float32)\n",
    "        if self.transform is not None:\n",
    "            t = torch.vstack((x,y))\n",
    "            t = self.transform(t)\n",
    "            x,y=t[:self.in_seq_len*self.channels_per_timestamp],t[self.in_seq_len*self.channels_per_timestamp:]\n",
    "        if self.with_time:\n",
    "            return (x, self.sequences[index][-1]), y\n",
    "        else:\n",
    "            return x, y\n",
    "\n",
    "    def prepare_array(self,temp,full_res):\n",
    "        temp[temp == -1e6] = 0\n",
    "        temp[temp == -2e6] = -0.001\n",
    "        temp[0,:]=-0.001\n",
    "        temp[:,-1]=-0.001\n",
    "        temp=torch.tensor(temp.astype(np.float16))\n",
    "        temp=F.pad(temp,(2,2,2,2),value=-0.001)\n",
    "        if(not full_res):\n",
    "            temp = v2.functional.resize(temp.unsqueeze(0),(128,128),antialias=False).squeeze(0)\n",
    "        return temp    \n",
    "    \n",
    "    def __prepare_dicts(self, folder,files):\n",
    "        for file in files:\n",
    "            with h5py.File(os.path.join(folder,file), mode='r') as d:\n",
    "                timestamps = d.keys()\n",
    "                for timestamp in tqdm(timestamps):\n",
    "                    temp=np.array(d[timestamp]['intensity'],dtype=np.float32)\n",
    "                    temp=self.prepare_array(temp,self.full_res)\n",
    "                    self.intensity[int(timestamp)]=temp\n",
    "                    \n",
    "                    temp=np.array(d[timestamp]['events'],dtype=np.float32)\n",
    "                    temp=self.prepare_array(temp,self.full_res)\n",
    "                    self.events[int(timestamp)]=temp\n",
    "                    \n",
    "                    temp=np.array(d[timestamp]['reflectivity'][0],dtype=np.float32)\n",
    "                    temp=self.prepare_array(temp,self.full_res)\n",
    "                    self.reflectivity0[int(timestamp)]=temp\n",
    "                    \n",
    "                    temp=np.array(d[timestamp]['reflectivity'][1],dtype=np.float32)\n",
    "                    temp=self.prepare_array(temp,self.full_res)\n",
    "                    self.reflectivity1[int(timestamp)]=temp\n",
    "\n",
    "    def __prepare_sequences(self, mode):\n",
    "        timestamps = np.unique(sorted(self.intensity.keys()))\n",
    "        if mode == 'sequentially':\n",
    "            self.sequences = [\n",
    "                timestamps[index * self.seq_len: (index + 1) * self.seq_len]\n",
    "                for index in range(len(timestamps) // self.seq_len)\n",
    "            ]\n",
    "        elif mode == 'overlap':\n",
    "            self.sequences = [\n",
    "                timestamps[index: index + self.seq_len]\n",
    "                for index in range(len(timestamps) - self.seq_len + 1)\n",
    "            ]\n",
    "        else:\n",
    "            raise Exception(f'Unknown mode {mode}')\n",
    "        self.sequences = list(filter(\n",
    "            lambda x: int(x[-1]) - int(x[0]) == (self.seq_len - 1) * 600,\n",
    "            self.sequences\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:25:40.398672Z",
     "iopub.status.busy": "2023-11-11T17:25:40.398382Z",
     "iopub.status.idle": "2023-11-11T17:25:49.066035Z",
     "shell.execute_reply": "2023-11-11T17:25:49.064936Z",
     "shell.execute_reply.started": "2023-11-11T17:25:40.398648Z"
    }
   },
   "outputs": [],
   "source": [
    "folder=\"/kaggle/input/yandex-cup-ml-23-nowcasting/ML Cup 2023 Weather\"\n",
    "files=['2022-test-public.hdf5']\n",
    "test_dataset=RadarDataset(folder,files,out_seq_len=0,mode='sequentially', with_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:25:49.067689Z",
     "iopub.status.busy": "2023-11-11T17:25:49.067369Z",
     "iopub.status.idle": "2023-11-11T17:46:50.176573Z",
     "shell.execute_reply": "2023-11-11T17:46:50.175114Z",
     "shell.execute_reply.started": "2023-11-11T17:25:49.067663Z"
    }
   },
   "outputs": [],
   "source": [
    "folder=\"/kaggle/input/yandex-cup-ml-23-nowcasting/ML Cup 2023 Weather/train\"\n",
    "files=os.listdir(folder)\n",
    "train_dataset=RadarDataset(folder,files,mode='overlap',full_res=False, transform = train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:46:50.178878Z",
     "iopub.status.busy": "2023-11-11T17:46:50.178414Z",
     "iopub.status.idle": "2023-11-11T17:46:50.198242Z",
     "shell.execute_reply": "2023-11-11T17:46:50.197349Z",
     "shell.execute_reply.started": "2023-11-11T17:46:50.178836Z"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block= nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3,padding=1),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Conv2d(out_ch, out_ch, 3,padding=1),\n",
    "            nn.LeakyReLU(0.1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs):\n",
    "        super().__init__()\n",
    "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
    "        self.pool       = nn.MaxPool2d(2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return ftrs\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs):\n",
    "        super().__init__()\n",
    "        self.chs         = chs\n",
    "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
    "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
    "        \n",
    "    def forward(self, x, encoder_features):\n",
    "        for i in range(len(self.chs)-1):\n",
    "            x        = self.upconvs[i](x)\n",
    "            x        = torch.cat([x, encoder_features[i]], dim=1)\n",
    "            x        = self.dec_blocks[i](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, enc_chs, dec_chs, num_class):\n",
    "        super().__init__()\n",
    "        self.encoder     = Encoder(enc_chs)\n",
    "        self.decoder     = Decoder(dec_chs)\n",
    "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 3,padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        if(x.shape[-1]==256):\n",
    "            x=v2.functional.resize(x,(128,128),antialias=False)\n",
    "            out=self._forward(x)\n",
    "            out=v2.functional.resize(out,(256,256),antialias=False)\n",
    "            return out\n",
    "        else:\n",
    "            return self._forward(x)\n",
    "        \n",
    "    def _forward(self, x):\n",
    "        enc_ftrs = self.encoder(x)\n",
    "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
    "        out      = self.head(out)\n",
    "        if self.training:\n",
    "            return out\n",
    "        else:\n",
    "            return nn.ReLU()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:46:50.199848Z",
     "iopub.status.busy": "2023-11-11T17:46:50.199464Z",
     "iopub.status.idle": "2023-11-11T17:46:50.213466Z",
     "shell.execute_reply": "2023-11-11T17:46:50.212602Z",
     "shell.execute_reply.started": "2023-11-11T17:46:50.199820Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_test(model, test_dataset,  output_file='output.hdf5', use_transforms=True):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    for index, item in enumerate(test_dataset):\n",
    "        (inputs, last_input_timestamp), _ = item\n",
    "        inputs = inputs.unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            if(use_transforms):\n",
    "                outs=[]\n",
    "                for i in range(8):\n",
    "                    outs.append(TEST_TRANSFORM_LIST_REVERSE[i](model(TEST_TRANSFORM_LIST[i](inputs))))\n",
    "                output=torch.stack(outs).mean(0)\n",
    "            else:\n",
    "                output = model(inputs)\n",
    "        with h5py.File(output_file, mode='a') as f_out:\n",
    "            for index in range(output.shape[1]):\n",
    "                timestamp_out = str(int(last_input_timestamp) + 600 * (index + 1))\n",
    "                f_out.create_group(timestamp_out)\n",
    "                f_out[timestamp_out].create_dataset(\n",
    "                    'intensity',\n",
    "                    data=output[0, index][2:-2,2:-2].detach().cpu().numpy().astype(np.float16)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:46:50.214956Z",
     "iopub.status.busy": "2023-11-11T17:46:50.214656Z",
     "iopub.status.idle": "2023-11-11T17:46:50.225173Z",
     "shell.execute_reply": "2023-11-11T17:46:50.224300Z",
     "shell.execute_reply.started": "2023-11-11T17:46:50.214923Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler):\n",
    "    model.train()\n",
    "    device = next(model.parameters()).device\n",
    "    for i,data in enumerate(loader):\n",
    "        x,y = data\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        mask = (y>=0).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss=torch.square((pred-y)*mask).sum((0,2,3))/y.shape[0]\n",
    "        loss=torch.sqrt(loss).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (scheduler is not None):\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:46:50.226384Z",
     "iopub.status.busy": "2023-11-11T17:46:50.226130Z",
     "iopub.status.idle": "2023-11-11T17:46:50.239807Z",
     "shell.execute_reply": "2023-11-11T17:46:50.238902Z",
     "shell.execute_reply.started": "2023-11-11T17:46:50.226360Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=451):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T17:46:50.242948Z",
     "iopub.status.busy": "2023-11-11T17:46:50.242633Z",
     "iopub.status.idle": "2023-11-11T21:04:43.854604Z",
     "shell.execute_reply": "2023-11-11T21:04:43.853701Z",
     "shell.execute_reply.started": "2023-11-11T17:46:50.242918Z"
    }
   },
   "outputs": [],
   "source": [
    "set_seed(294)\n",
    "\n",
    "NUM_EPOCHS=45\n",
    "LR=5e-4\n",
    "BATCH_SIZE=8\n",
    "PCT_START=0.3\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model=UNet(enc_chs=(16,32,64,128,256), dec_chs=(256,128,64,32), num_class=12).to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler=torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=LR,pct_start=PCT_START,steps_per_epoch=len(train_loader), epochs=NUM_EPOCHS)\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    train_epoch(model, train_loader, optimizer, scheduler)\n",
    "    process_test(model, test_dataset,  output_file=os.path.join('..','individual_predictions',f'FINAL-SIX-{epoch:02}.hdf5'), use_transforms=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
